{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV and PDF Manipulation with Python:\n",
    "\n",
    "## Review Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Write script, read data from pastimes.csv, skip header row (next()). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Arturo/Desktop/book1-exercises/chp09/practice_files/pastimes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c6b6efe46217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#NB: '\\' reads this as escape character. If you use '/', it should be okay.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"pastimes.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmy_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcsv_file_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_reader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#skips header row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Arturo/Desktop/book1-exercises/chp09/practice_files/pastimes.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "my_path= 'C:/Users/Arturo/Desktop/book1-exercises/chp09/practice_files/' \n",
    "#NB: '\\' reads this as escape character. If you use '/', it should be okay.  \n",
    "\n",
    "with open(os.path.join(my_path,\"pastimes.csv\"),\"r\") as my_file:\n",
    "    csv_file_reader = csv.reader(my_file)\n",
    "    next(csv_file_reader) #skips header row\n",
    "    for row in csv_file_reader:\n",
    "        print(row, type(row))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Display each row as list of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Fezzik, pastime: Fighting\n",
      "name: Westley, pastime: Winning\n",
      "name: Inigo Montoya, pastime: Sword fighting\n",
      "name: Buttercup, pastime: Complaining\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(my_path,\"pastimes.csv\"),\"r\") as my_file:\n",
    "    csv_file_reader = csv.reader(my_file)\n",
    "    next(csv_file_reader)\n",
    "    for name,pastime in csv_file_reader:\n",
    "        print('name: {}, pastime: {}'.format(name,pastime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Favorite Pastime, all lowercase, if second part, all in lowercase is \"fighting\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fezzik likes figthing\n",
      "Inigo Montoya likes figthing\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(my_path,\"pastimes.csv\"),\"r\") as my_file:\n",
    "    csv_file_reader = csv.reader(my_file)\n",
    "    next(csv_file_reader)\n",
    "    for name,pastime in csv_file_reader:\n",
    "        if pastime.lower().find('fighting') != -1:\n",
    "            print(name, 'likes figthing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Add new column, append \"Combat\" or \"Other\" if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Fezzik', 'Fighting', 'Combat'], ['Westley', 'Winning', 'Other'], ['Inigo Montoya', 'Sword fighting', 'Combat'], ['Buttercup', 'Complaining', 'Other']]\n"
     ]
    }
   ],
   "source": [
    "data_pastime=[]\n",
    "\n",
    "with open(os.path.join(my_path,\"pastimes.csv\"),\"r\") as my_file:\n",
    "    csv_file_reader = csv.reader(my_file)\n",
    "    next(csv_file_reader) #skips header row\n",
    "    for row in csv_file_reader:\n",
    "        if row[1].lower().find('fighting') != -1:\n",
    "            row.append('Combat')\n",
    "        else:\n",
    "            row.append('Other')\n",
    "        data_pastime.append(row)\n",
    "\n",
    "print(data_pastime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Make new csv with updated data, new header, new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(my_path,\"categorized_pastimes.csv\"),\"w\",  newline='') as my_file:\n",
    "    csv_file_writer = csv.writer(my_file)\n",
    "    csv_file_writer.writerow(['Name','Favorite Pastime','Type of Pastime'])\n",
    "    csv_file_writer.writerows(data_pastime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Manipulation\n",
    "\n",
    "### Revew Exercises\n",
    "\n",
    "1) Get Data about a PDF containing the text of \"The Whistling Gypsy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author:  Leo Maguire\n",
      "Title:  The Whistling Gypsy\n",
      "Number of Pages:  2\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfFileReader,PdfFileWriter\n",
    "\n",
    "pdf_path=\"C:/Users/Arturo/Desktop/book1-exercises/chp11/practice_files/\"\n",
    "\n",
    "pdf_file_name= os.path.join(pdf_path,\"The Whistling Gypsy.pdf\")\n",
    "pdf_file_read= PdfFileReader(open(pdf_file_name, 'rb'))\n",
    "\n",
    "print('Author: ', pdf_file_read.getDocumentInfo().author)\n",
    "print('Title: ', pdf_file_read.getDocumentInfo().title)\n",
    "print('Number of Pages: ', pdf_file_read.getNumPages())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Extract contents of Whistling Gypsy into .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\ufb01' in position 788: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e3292a708d27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_pages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdf_file_read\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetPage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\ufb01' in position 788: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "pdf_output_file_name = os.path.join(pdf_path,\"The Whistling Gypsy.txt\")\n",
    "output_file = open(pdf_output_file_name, \"w\")\n",
    "\n",
    "total_pages = pdf_file_read.getNumPages()\n",
    "\n",
    "for page in range(0, total_pages):\n",
    "    text = pdf_file_read.getPage(page).extractText()\n",
    "    output_file.write(text)\n",
    "    \n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reportlab.pdfgen import canvas\n",
    "c = canvas.Canvas(\"hello.pdf\")\n",
    "c.drawString(250, 500, \"Hello World\")\n",
    "c.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Jean-Baptiste Zorg', 122)\n",
      "('Korben Dallas', 100)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "entity_values=(('Jean-Baptiste Zorg', 'Human', 122),\n",
    "('Korben Dallas', 'Meat Popsicle', 100),\n",
    "(\"Ak'not\", 'Mangalore', -5))\n",
    "\n",
    "with sqlite3.connect(':memory:') as connection:\n",
    "    curs = connection.cursor()\n",
    "    curs.execute(\"CREATE TABLE Roster(Name TEXT, Species TEXT, IQ INT)\")\n",
    "    curs.executemany(\"INSERT INTO Roster VALUES(?, ?, ?)\", entity_values)\n",
    "    curs.execute(\"UPDATE Roster SET Species=? WHERE Name=?\",\n",
    "('Human', 'Korben Dallas'))\n",
    "    curs.execute(\"SELECT Name, IQ FROM Roster Where Species = 'Human'\")\n",
    "    #curs.execute(\"SELECT * FROM Roster\")\n",
    "    for row in curs.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Web Scraping and Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>Profile: Aphrodite</title>\n",
      "</head>\n",
      "<body bgcolor=\"yellow\">\n",
      "<center>\n",
      "<br><br>\n",
      "<img src=\"aphrodite.gif\" />\n",
      "<h2>Name: Aphrodite</h2>\n",
      "<br><br>\n",
      "Favorite animal: Dove\n",
      "<br><br>\n",
      "Favorite color: Red\n",
      "<br><br>\n",
      "Hometown: Mount Olympus\n",
      "</center>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "my_address = \"https://realpython.com/practice/aphrodite.html\"\n",
    "html_page = urlopen(my_address)\n",
    "html_text = html_page.read().decode('utf-8')\n",
    "print (html_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Exercises\n",
    "\n",
    "### 1. Write a script that grabs the full HTML from the page dionysus.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<TITLE >Profile: Dionysus</title  / >\\n</head>\\n<body bgcolor=\"yellow\">\\n<center>\\n<br><br>\\n<img src=\"dionysus.jpg\" />\\n<h2>Name: Dionysus</h2>\\n<img src=\"grapes.png\"><br><br>\\nHometown: Mount Olympus\\n<br><br>\\nFavorite animal: Leopard <br>\\n<br>\\nFavorite Color: Wine\\n</center>\\n</body>\\n</html>' <class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "my_address = \"https://realpython.com/practice/dionysus.html\"\n",
    "html_page = urlopen(my_address)\n",
    "html_text = html_page.read()\n",
    "print (html_text, type(html_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use the string find() method to display the text following \"Name:\" and \"Favorite Color:\" (not including any leading spaces or trailing HTML tags that might appear on the same line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Dionysus , Favorite Color: Wine\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "my_address = \"https://realpython.com/practice/dionysus.html\"\n",
    "html_page = urlopen(my_address)\n",
    "html_text = html_page.read().decode('utf-8')\n",
    "\n",
    "#Pulling out the name\n",
    "start_name_index= html_text.find('Name:')+len('Name:')\n",
    "end_name_index = html_text.find('</h2>')\n",
    "name= html_text[start_name_index:end_name_index].strip()\n",
    "\n",
    "#Favorite Color\n",
    "start_favcol_index = html_text.find('Favorite Color:')+len('Favorite Color:')\n",
    "end_favcol_index = html_text.find('</center>')\n",
    "favcol= html_text[start_favcol_index:end_favcol_index].strip()\n",
    "print ('Name:', name, ', Favorite Color:', favcol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Repeat the previous exercise using regular expressions; the end of each pattern should be a \"<\" (i.e., the start of an HTML tag) or a newline character, and you should remove any extra spaces or newline characters from the resulting text using the string strip() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dionysus\n",
      "Wine 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "name_search = re.search(r\"(>Name:)(.*)(<)\",html_text, re.IGNORECASE)\n",
    "name_results = name_search.group(2).strip()\n",
    "\n",
    "print(name_results)\n",
    "\n",
    "\n",
    "favcol_search = re.search(r\"(\\s*)(Color:)(.*)(\\s*)(<)\", html_text, re.IGNORECASE)\n",
    "favcol_results = favcol_search.group(3).strip()\n",
    "print(favcol_results, len(favcol_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Profile: Dionysus\n",
      "  </title>\n",
      " </head>\n",
      " <body bgcolor=\"yellow\">\n",
      "  <center>\n",
      "   <br/>\n",
      "   <br/>\n",
      "   <img src=\"dionysus.jpg\"/>\n",
      "   <h2>\n",
      "    Name: Dionysus\n",
      "   </h2>\n",
      "   <img src=\"grapes.png\"/>\n",
      "   <br/>\n",
      "   <br/>\n",
      "   Hometown: Mount Olympus\n",
      "   <br/>\n",
      "   <br/>\n",
      "   Favorite animal: Leopard\n",
      "   <br/>\n",
      "   <br/>\n",
      "   Favorite Color: Wine\n",
      "  </center>\n",
      " </body>\n",
      "</html> <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "my_address = \"https://realpython.com/practice/dionysus.html\"\n",
    "html_page = urlopen(my_address)\n",
    "html_text = html_page.read() # Py 3: decode\n",
    "my_soup = BeautifulSoup(html_text, 'lxml')\n",
    "\n",
    "print(my_soup.prettify(), type(my_soup.prettify()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   All Profiles\n",
      "  </title>\n",
      " </head>\n",
      " <body bgcolor=\"yellow\">\n",
      "  <center>\n",
      "   <br/>\n",
      "   <br/>\n",
      "   <h1>\n",
      "    All Profiles:\n",
      "   </h1>\n",
      "   <br/>\n",
      "   <br/>\n",
      "   <h2>\n",
      "    <a href=\"aphrodite.html\">\n",
      "     Aphrodite\n",
      "    </a>\n",
      "    <br/>\n",
      "    <br/>\n",
      "    <a href=\"poseidon.html\">\n",
      "     Poseidon\n",
      "    </a>\n",
      "    <br/>\n",
      "    <br/>\n",
      "    <a href=\"dionysus.html\">\n",
      "     Dionysus\n",
      "    </a>\n",
      "   </h2>\n",
      "  </center>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "my_address = \"https://realpython.com/practice/profiles.html\"\n",
    "html_page = urlopen(my_address)\n",
    "html_text = html_page.read() # Py 3: decode\n",
    "my_divine_soup = BeautifulSoup(html_text, 'lxml')\n",
    "\n",
    "print(my_divine_soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"aphrodite.html\">Aphrodite</a>, <a href=\"poseidon.html\">Poseidon</a>, <a href=\"dionysus.html\">Dionysus</a>]\n",
      "[<a href=\"aphrodite.html\">Aphrodite</a>, <a href=\"poseidon.html\">Poseidon</a>, <a href=\"dionysus.html\">Dionysus</a>]\n"
     ]
    }
   ],
   "source": [
    "print(my_divine_soup('a'))\n",
    "print(my_divine_soup.find_all('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "href_type_list = [(href['href'], type(href)) for href in my_divine_soup.find_all('a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aphrodite.html', <class 'bs4.element.Tag'>), ('poseidon.html', <class 'bs4.element.Tag'>), ('dionysus.html', <class 'bs4.element.Tag'>)]\n"
     ]
    }
   ],
   "source": [
    "print(href_type_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Get the HTML from each of the pages in the list by adding the full path to the file name, and display the text (without HTML tags) on each page using Beautiful Soup's get_text() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "href_list = [href['href'] for href in my_divine_soup.find_all('a')]\n",
    "print(type(href_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_address = \"https://realpython.com/practice/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Profile: Aphrodite\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Name: Aphrodite\n",
      "\n",
      "Favorite animal: Dove\n",
      "\n",
      "Favorite color: Red\n",
      "\n",
      "Hometown: Mount Olympus\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Profile: Poseidon\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Name: Poseidon\n",
      "\n",
      "Favorite animal: Dolphin\n",
      "\n",
      "Favorite color: Blue\n",
      "\n",
      "Hometown: Sea\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Profile: Dionysus\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Name: Dionysus\n",
      "\n",
      "Hometown: Mount Olympus\n",
      "\n",
      "Favorite animal: Leopard \n",
      "\n",
      "Favorite Color: Wine\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for href in href_list:\n",
    "    temp_address = base_address+href\n",
    "    html_page = urlopen(temp_address)\n",
    "    html_text = html_page.read() # Py 3: decode\n",
    "    my_temp_soup = BeautifulSoup(html_text, 'lxml')\n",
    "    print(my_temp_soup.get_text())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Mechanical Soup Exercises\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>Log In</title>\n",
      "</head>\n",
      "<body bgcolor=\"yellow\">\n",
      "<center>\n",
      "<br/><br/>\n",
      "<h2>Please log in to access Mount Olympus:</h2>\n",
      "<br/><br/>\n",
      "<form action=\"login.php\" method=\"post\" name=\"login\">\n",
      "Username: <input name=\"user\" type=\"text\"/><br/>\n",
      "Password: <input name=\"pwd\" type=\"password\"/><br/><br/>\n",
      "<input type=\"submit\" value=\"Submit\"/>\n",
      "</form>\n",
      "</center>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "#Test Code:\n",
    "import mechanicalsoup\n",
    "my_browser = mechanicalsoup.Browser()\n",
    "page = my_browser.get(\"https://realpython.com/practice/login.php\")\n",
    "print(page.soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 \n",
    "Use MechanicalSoup to provide the correct username \"zeus\" and password\n",
    "\"ThunderDude\" to the login page submission form located at:\n",
    "https://realpython.com/practice/login.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://realpython.com/practice/profiles.html\n",
      "<html>\n",
      "<head>\n",
      "<title>All Profiles</title>\n",
      "</head>\n",
      "<body bgcolor=\"yellow\">\n",
      "<center>\n",
      "<br/><br/>\n",
      "<h1>All Profiles:</h1>\n",
      "<br/><br/>\n",
      "<h2>\n",
      "<a href=\"aphrodite.html\">Aphrodite</a>\n",
      "<br/><br/>\n",
      "<a href=\"poseidon.html\">Poseidon</a>\n",
      "<br/><br/>\n",
      "<a href=\"dionysus.html\">Dionysus</a>\n",
      "</h2>\n",
      "</center>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import mechanicalsoup\n",
    "my_browser = mechanicalsoup.Browser()\n",
    "login_page = my_browser.get(\"https://realpython.com/practice/login.php\")\n",
    "login_html = login_page.soup\n",
    "# select the form and fill in its fields\n",
    "form = login_html.select(\"form\")[0]\n",
    "form.select(\"input\")[0][\"value\"] = \"zeus\"\n",
    "form.select(\"input\")[1][\"value\"] = \"ThunderDude\"\n",
    "profiles_page = my_browser.submit(form, login_page.url) # submit form\n",
    "print(profiles_page.url) # make sure we were redirected\n",
    "print(profiles_page.soup) # show html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 \n",
    "Using Beautiful Soup, display the title of the current page to determine that you\n",
    "have been redirected to profiles.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".text,  Alfive <class 'str'>\n",
      ".string,  Alfive <class 'bs4.element.NavigableString'>\n"
     ]
    }
   ],
   "source": [
    "print('.text, ',profiles_page.soup.title.text[0:2]+'five', type(profiles_page.soup.title.text))\n",
    "print('.string, ',profiles_page.soup.title.string[0:2]+'five', type(profiles_page.soup.title.string))\n",
    "#print(profiles_page.soup.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://realpython.com/practice/profiles.html\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "my_address = \"https://realpython.com/practice/profiles.html\"\n",
    "html_page = urlopen(my_address)\n",
    "html_text = html_page.read() # Py 3: decode\n",
    "my_soup = BeautifulSoup(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL Price:  149.04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(0, 3):\\n    page = my_browser.get(\"https://finance.yahoo.com/quote/AAPL/?p=AAPL\")\\n    html_text = page.soup\\n    # return a list of all the tags where the id is \\'yfs_184_yhoo\\'\\n    my_tags = html_text.select(\"span.Trsdu(0.3s)\")\\n    # take the BeautifulSoup string out of the first tag\\n    my_price = my_tags.text\\n    print(\"The current price of AAPL is: {}, call:{}\".format(my_price, i+1))\\n\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Yahoo Problem:\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "my_new_address = \"https://finance.yahoo.com/quote/AAPL/?p=AAPL\"\n",
    "html_page = urlopen(my_new_address)\n",
    "html_text = html_page.read() # Py 3: decode\n",
    "my_new_soup = BeautifulSoup(html_text)\n",
    "stockprice= my_new_soup.find('span', attrs={'data-reactid':36})\n",
    "print('AAPL Price: ', stockprice.text)\n",
    "#Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(ib)\n",
    "\n",
    "'''\n",
    "for i in range(0, 3):\n",
    "    page = my_browser.get(\"https://finance.yahoo.com/quote/AAPL/?p=AAPL\")\n",
    "    html_text = page.soup\n",
    "    # return a list of all the tags where the id is 'yfs_184_yhoo'\n",
    "    my_tags = html_text.select(\"span.Trsdu(0.3s)\")\n",
    "    # take the BeautifulSoup string out of the first tag\n",
    "    my_price = my_tags.text\n",
    "    print(\"The current price of AAPL is: {}, call:{}\".format(my_price, i+1))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
